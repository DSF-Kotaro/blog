{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "図解速習DeepLearning_#010.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJQA1d6IndAj4H155y5Bvh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSF-Kotaro/blog/blob/main/%E5%9B%B3%E8%A7%A3%E9%80%9F%E7%BF%92DeepLearning_010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY40BZkVDLI0",
        "outputId": "d1980482-e8e5-45d6-da5c-faf5c0f7870d"
      },
      "source": [
        "!git clone https://github.com/pkmital/CycleGAN.git\r\n",
        "!pip install cadl"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CycleGAN' already exists and is not an empty directory.\n",
            "Collecting cadl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/a9/fff67bf2f284c85ddd54108e35b2e9db8e6a3deef9a4c083ed73ed11bc37/cadl-1.1.0-py3-none-any.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cadl) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cadl) (1.19.5)\n",
            "Collecting magenta\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/d5/e2de33a9456850f8a17bd977a87c1b51e3866d5c982da0d833714ce829b4/magenta-2.1.3-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from cadl) (0.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from cadl) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cadl) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from cadl) (3.2.5)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from cadl) (0.8.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from cadl) (0.0.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from cadl) (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cadl) (2.23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cadl) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cadl) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cadl) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cadl) (1.3.1)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 17.3MB/s \n",
            "\u001b[?25hCollecting numba<0.50\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/dc/0e3d3732fd62c73fbb3317fc7bba22574832ab7a8e075620557bd4311641/numba-0.49.1-cp36-cp36m-manylinux2014_x86_64.whl (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from magenta->cadl) (0.10.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from magenta->cadl) (0.36.2)\n",
            "Collecting mir-eval>=0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/fe/be4f7a59ed71938e21e89f23afe93eea0d39eb3e77f83754a12028cf1a68/mir_eval-0.6.tar.gz (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from magenta->cadl) (2.4.1)\n",
            "Collecting sox>=1.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/67/1810e9a69956eb236967b7174c11fd8d8c2cdab051509286f72e6c7e147e/sox-1.4.1-py2.py3-none-any.whl\n",
            "Collecting pygtrie>=2.3\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/8b/90d0f21a27a354e808a73eb0ffb94db990ab11ad1d8b3db3e5196c882cad/pygtrie-2.4.2.tar.gz\n",
            "Collecting tensor2tensor\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/7c/9e87d30cefad5cbc390bb7f626efb3ded9b19416b8160f1a1278da81b218/tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 44.4MB/s \n",
            "\u001b[?25hCollecting note-seq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/00/309c6b1df4e23e5e2737251bf27a8dba5f7c273234ab1bdd77604ae56ca9/note_seq-0.0.2-py3-none-any.whl (209kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from magenta->cadl) (4.0.1)\n",
            "Collecting dm-sonnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/28/9185afffefb655ef1a29f4b84aa9f656826408ca2d1b9ffeba81fbfd40ec/dm_sonnet-2.0.0-py3-none-any.whl (254kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 49.6MB/s \n",
            "\u001b[?25hCollecting mido==1.2.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/51/447066f537e05996a4579829b93390a4d85b0e3da90c5fbc34c1e70a37d5/mido-1.2.6-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dopamine-rl<=3.0.1 in /usr/local/lib/python3.6/dist-packages (from magenta->cadl) (1.0.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from magenta->cadl) (1.15.0)\n",
            "Collecting pretty-midi>=0.2.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/8e/63c6e39a7a64623a9cd6aec530070c70827f6f8f40deec938f323d7b1e15/pretty_midi-0.2.9.tar.gz (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=3.4.2 in /usr/local/lib/python3.6/dist-packages (from magenta->cadl) (7.0.0)\n",
            "Collecting sk-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/3f/ce848b8b2062ad1ccf1449094a740c775f6c761339f411e44f1e090f23a7/sk_video-1.1.10-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 50.2MB/s \n",
            "\u001b[?25hCollecting python-rtmidi<1.2,>=1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/78/16f6d12abfccb6b1d330b1e1c6228536fa8d8ef6c14d560aba20176f044c/python-rtmidi-1.1.2.tar.gz (204kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from magenta->cadl) (0.12.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->cadl) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->cadl) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->cadl) (1.0.0)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from librosa->cadl) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->cadl) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa->cadl) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->cadl) (2.1.9)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.6/dist-packages (from librosa->cadl) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->cadl) (4.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (2.4.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (2.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (0.3.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->cadl) (0.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cadl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cadl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cadl) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cadl) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba<0.50->magenta->cadl) (53.0.0)\n",
            "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fd/d029b53b19200a2b98bed69ba0354b37c236b44a93b34b3075c4aaab2d03/llvmlite-0.32.1-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from mir-eval>=0.4->magenta->cadl) (0.16.0)\n",
            "Collecting mesh-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/20/23bbc94034e16bb1ace73e9e7922226e31d6d36b88dcfa257d2c59b3f465/mesh_tensorflow-0.1.18-py3-none-any.whl (361kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 36.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (0.4.0)\n",
            "Collecting kfac\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/36/06fe2c757044bb51906fef231ac48cc5bf9a277fc9a8c7e1108d7e9e8cfd/kfac-0.2.3-py2.py3-none-any.whl (191kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 51.2MB/s \n",
            "\u001b[?25hCollecting pypng\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 43.7MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (4.41.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (4.1.3)\n",
            "Collecting gevent\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/90/000736e587a720f8eef2bcd384456ce2add5ddfc3c63cf51a7ea13412cb6/gevent-21.1.2-cp36-cp36m-manylinux2010_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (0.8.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (4.1.2.30)\n",
            "Collecting tensorflow-gan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/2e/62922111d7d50e1900e3030764743ea7735540ce103b3ab30fd5cd2d8a2b/tensorflow_gan-2.0.0-py2.py3-none-any.whl (365kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 39.0MB/s \n",
            "\u001b[?25hCollecting bz2file\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (1.7.12)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (1.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (1.1.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->magenta->cadl) (0.17.3)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from note-seq->magenta->cadl) (1.1.5)\n",
            "Requirement already satisfied: bokeh>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from note-seq->magenta->cadl) (2.1.1)\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: intervaltree>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from note-seq->magenta->cadl) (2.1.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from note-seq->magenta->cadl) (20.3.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from note-seq->magenta->cadl) (5.5.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->magenta->cadl) (5.1.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->magenta->cadl) (0.1.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->magenta->cadl) (2.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->magenta->cadl) (0.8)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->magenta->cadl) (0.27.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->magenta->cadl) (0.3.3)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet->magenta->cadl) (0.8.7)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->magenta->cadl) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa->cadl) (1.14.4)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa->cadl) (1.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa->cadl) (20.8)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->cadl) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->cadl) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->cadl) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->cadl) (1.24.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow->cadl) (1.8.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor->magenta->cadl) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor->magenta->cadl) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor->magenta->cadl) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor->magenta->cadl) (0.17.4)\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/b0/da8afd9b3bd50c7665ecdac062f182982af1173c9081f9af7261091c5588/zope.interface-5.2.0-cp36-cp36m-manylinux2010_x86_64.whl (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 34.1MB/s \n",
            "\u001b[?25hCollecting greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/e2/9fbb24cf1ee89813ded3761314562a83a2822ad2bf5682eef0d0c99e2a5d/greenlet-1.0.0-cp36-cp36m-manylinux2010_x86_64.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 40.2MB/s \n",
            "\u001b[?25hCollecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tensor2tensor->magenta->cadl) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gan->tensor2tensor->magenta->cadl) (0.11.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor->magenta->cadl) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor->magenta->cadl) (3.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor->magenta->cadl) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor->magenta->cadl) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor->magenta->cadl) (1.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->tensor2tensor->magenta->cadl) (1.1.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->tensor2tensor->magenta->cadl) (1.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->note-seq->magenta->cadl) (2018.9)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh>=0.12.0->note-seq->magenta->cadl) (3.13)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh>=0.12.0->note-seq->magenta->cadl) (5.1.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from intervaltree>=2.1.0->note-seq->magenta->cadl) (2.3.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->note-seq->magenta->cadl) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->note-seq->magenta->cadl) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->note-seq->magenta->cadl) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->note-seq->magenta->cadl) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->note-seq->magenta->cadl) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->note-seq->magenta->cadl) (0.7.5)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->magenta->cadl) (3.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->magenta->cadl) (1.52.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa->cadl) (2.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->cadl) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->cadl) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->cadl) (4.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->tensor2tensor->magenta->cadl) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->note-seq->magenta->cadl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->note-seq->magenta->cadl) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->note-seq->magenta->cadl) (0.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->cadl) (3.1.0)\n",
            "Building wheels for collected packages: mir-eval, pygtrie, pretty-midi, python-rtmidi, pypng, bz2file\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.6-cp36-none-any.whl size=96515 sha256=d90b594b2674a06f33195cef3c9c45e453fb6e2efd7f663b13c0e55ffb2e24e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ce/30/730fa72addf275e49d90683b01b3613048b4be3bf7ff8eb6ec\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.4.2-cp36-none-any.whl size=19063 sha256=4b165b05f89c24323b05149e992e8ee4e66b9356f0f02a8e79eeb4a8c1653438\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/57/91/73782136379fe419036c5ec0e4070d8b3a35f2a36bd6a94ed8\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-cp36-none-any.whl size=5591954 sha256=cc223bd3705abae9b2c7e3a2cd3d37f7336c67b4e7a721467af6c78e6ca4735a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/a1/c6/b5697841db1112c6e5866d75a6b6bf1bef73b874782556ba66\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-rtmidi: filename=python_rtmidi-1.1.2-cp36-cp36m-linux_x86_64.whl size=389862 sha256=f448509efa7cc2bae8492edbea13399561a21b8fbe594190a0313a567d0b0a41\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/9d/55/0554f02fbc777976865e0ea603028a0f87854b7df385ffa366\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-cp36-none-any.whl size=67161 sha256=97d705ff86be6b9f652341fb3699359d4cec78cc8c6d13134889c68246c9d3f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-cp36-none-any.whl size=6883 sha256=92a2b5fbf2006cf1ec973020dde05ccb71b7f7b6216c3bf628209a1409be8664\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built mir-eval pygtrie pretty-midi python-rtmidi pypng bz2file\n",
            "\u001b[31mERROR: pynndescent 0.5.1 has requirement numba>=0.51.2, but you'll have numba 0.49.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.12.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.12.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: note-seq 0.0.2 has requirement numba==0.48.0, but you'll have numba 0.49.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 2.1.3 has requirement librosa<0.8.0,>=0.6.2, but you'll have librosa 0.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tf-slim, llvmlite, numba, mir-eval, sox, pygtrie, mesh-tensorflow, kfac, pypng, gunicorn, zope.interface, greenlet, zope.event, gevent, tensorflow-gan, bz2file, tensor2tensor, mido, pretty-midi, pydub, note-seq, dm-sonnet, sk-video, python-rtmidi, magenta, cadl\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed bz2file-0.98 cadl-1.1.0 dm-sonnet-2.0.0 gevent-21.1.2 greenlet-1.0.0 gunicorn-20.0.4 kfac-0.2.3 llvmlite-0.32.1 magenta-2.1.3 mesh-tensorflow-0.1.18 mido-1.2.6 mir-eval-0.6 note-seq-0.0.2 numba-0.49.1 pretty-midi-0.2.9 pydub-0.24.1 pygtrie-2.4.2 pypng-0.0.20 python-rtmidi-1.1.2 sk-video-1.1.10 sox-1.4.1 tensor2tensor-1.15.7 tensorflow-gan-2.0.0 tf-slim-1.1.0 zope.event-4.5.0 zope.interface-5.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "g6JdkMyADvfC",
        "outputId": "98509e70-182c-47af-c73c-c3fc99a6ab9f"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow.contrib.layers as tfl\r\n",
        "from cadl.cycle_gan import lrelu, instance_norm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6e71d5ae38b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcadl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle_gan\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWp9Z5T8EBpZ"
      },
      "source": [
        "def encoder(x, n_filters=32, k_size=3, normalizer_fn=instance_norm,\r\n",
        "        activation_fn=lrelu, scope=None, reuse=None):\r\n",
        "    with tf.variable_scope(scope or 'encoder', reuse=reuse):\r\n",
        "        h = tf.pad(x, [[0, 0], [k_size, k_size], [k_size, k_size], [0, 0]],\r\n",
        "                \"REFLECT\")\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_filters,\r\n",
        "                kernel_size=7,\r\n",
        "                stride=1,\r\n",
        "                padding='VALID',\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                scope='1',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_filters * 2,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=2,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                scope='2',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_filters * 4,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=2,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                scope='3',\r\n",
        "                reuse=reuse)\r\n",
        "    return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8U6QrFIEpd9"
      },
      "source": [
        "\r\n",
        "def residual_block(x, n_channels=128, normalizer_fn=instance_norm,\r\n",
        "        activation_fn=lrelu, kernel_size=3, scope=None, reuse=None):\r\n",
        "    with tf.variable_scope(scope or 'residual', reuse=reuse):\r\n",
        "        h = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_channels,\r\n",
        "                kernel_size=kernel_size,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                padding='VALID',\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                scope='1',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_channels,\r\n",
        "                kernel_size=kernel_size,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                padding='VALID',\r\n",
        "                activation_fn=None,\r\n",
        "                scope='2',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tf.add(x, h)\r\n",
        "    return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_QnHgZ7Erq8"
      },
      "source": [
        "def transform(x, img_size=256, reuse=None):\r\n",
        "    h = x\r\n",
        "    if img_size >= 256:\r\n",
        "        n_blocks = 9\r\n",
        "    else:\r\n",
        "        n_blocks = 6\r\n",
        "    for block_i in range(n_blocks):\r\n",
        "        with tf.variable_scope('block_{}'.format(block_i), reuse=reuse):\r\n",
        "            h = residual_block(h, reuse=reuse)\r\n",
        "    return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob2PkS3eEu1c"
      },
      "source": [
        "def decoder(x, n_filters=32, k_size=3, normalizer_fn=instance_norm,\r\n",
        "        activation_fn=lrelu, scope=None, reuse=None):\r\n",
        "    with tf.variable_scope(scope or 'decoder', reuse=reuse):\r\n",
        "        h = tfl.conv2d_transpose(\r\n",
        "                inputs=x,\r\n",
        "                num_outputs=n_filters * 2,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=2,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                scope='1',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tfl.conv2d_transpose(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_filters,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=2,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                scope='2',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tf.pad(h, [[0, 0], [k_size, k_size], [k_size, k_size], [0, 0]],\r\n",
        "                \"REFLECT\")\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=3,\r\n",
        "                kernel_size=7,\r\n",
        "                stride=1,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                padding='VALID',\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                activation_fn=tf.nn.tanh,\r\n",
        "                scope='3',\r\n",
        "                reuse=reuse)\r\n",
        "    return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-xHGPRYEwuM"
      },
      "source": [
        "def generator(x, scope=None, reuse=None):\r\n",
        "    img_size = x.get_shape().as_list()[1]\r\n",
        "    with tf.variable_scope(scope or 'generator', reuse=reuse):\r\n",
        "        h = encoder(x, reuse=reuse)\r\n",
        "        h = transform(h, img_size, reuse=reuse)\r\n",
        "        h = decoder(h, reuse=reuse)\r\n",
        "    return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD1n70KeE0Y1"
      },
      "source": [
        "plt.figure(figsize=(13,10))\r\n",
        "plt.imshow(plt.imread('CycleGAN/imgs/receptive-field-sizes.png'))\r\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odujuT2QE4G0"
      },
      "source": [
        "\r\n",
        "def discriminator(x, n_filters=64, k_size=4, activation_fn=lrelu,\r\n",
        "        normalizer_fn=instance_norm, scope=None, reuse=None):\r\n",
        "    with tf.variable_scope(scope or 'discriminator', reuse=reuse):\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=x,\r\n",
        "                num_outputs=n_filters,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=2,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                normalizer_fn=None,\r\n",
        "                scope='1',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_filters * 2,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=2,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                scope='2',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_filters * 4,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=2,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                scope='3',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=n_filters * 8,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=1,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                activation_fn=activation_fn,\r\n",
        "                normalizer_fn=normalizer_fn,\r\n",
        "                scope='4',\r\n",
        "                reuse=reuse)\r\n",
        "        h = tfl.conv2d(\r\n",
        "                inputs=h,\r\n",
        "                num_outputs=1,\r\n",
        "                kernel_size=k_size,\r\n",
        "                stride=1,\r\n",
        "                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\r\n",
        "                biases_initializer=None,\r\n",
        "                activation_fn=tf.nn.sigmoid,\r\n",
        "                scope='5',\r\n",
        "                reuse=reuse)\r\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkOOeghbE59c"
      },
      "source": [
        "img_size = 256\r\n",
        "X_real = tf.placeholder(name='X', shape=[1, img_size, img_size, 3], dtype=tf.float32)\r\n",
        "Y_real = tf.placeholder(name='Y', shape=[1, img_size, img_size, 3], dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYj2vjasE8yN"
      },
      "source": [
        "\r\n",
        "X_fake = generator(Y_real, scope='G_yx')\r\n",
        "Y_fake = generator(X_real, scope='G_xy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gozJnS0oE_NE"
      },
      "source": [
        "\r\n",
        "X_cycle = generator(Y_fake, scope='G_yx', reuse=True)\r\n",
        "Y_cycle = generator(X_fake, scope='G_xy', reuse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irS3tS0wFBZc"
      },
      "source": [
        "D_X_real = discriminator(X_real, scope='D_X')\r\n",
        "D_Y_real = discriminator(Y_real, scope='D_Y')\r\n",
        "D_X_fake = discriminator(X_fake, scope='D_X', reuse=True)\r\n",
        "D_Y_fake = discriminator(Y_fake, scope='D_Y', reuse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtAP8oMZFDN0"
      },
      "source": [
        "l1 = 10.0\r\n",
        "loss_cycle = tf.reduce_mean(l1 * tf.abs(X_real - X_cycle)) + \\\r\n",
        "             tf.reduce_mean(l1 * tf.abs(Y_real - Y_cycle))\r\n",
        "loss_G_xy = tf.reduce_mean(tf.square(D_Y_fake - 1.0)) + loss_cycle\r\n",
        "loss_G_yx = tf.reduce_mean(tf.square(D_X_fake - 1.0)) + loss_cycle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu7wqctkFFtM"
      },
      "source": [
        "X_fake_sample = tf.placeholder(name='X_fake_sample',\r\n",
        "        shape=[None, img_size, img_size, 3], dtype=tf.float32)\r\n",
        "Y_fake_sample = tf.placeholder(name='Y_fake_sample',\r\n",
        "        shape=[None, img_size, img_size, 3], dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iinOs6wdFHns"
      },
      "source": [
        "\r\n",
        "D_X_fake_sample = discriminator(X_fake_sample, scope='D_X', reuse=True)\r\n",
        "D_Y_fake_sample = discriminator(Y_fake_sample, scope='D_Y', reuse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Tcta_1FJwm"
      },
      "source": [
        "loss_D_Y = (tf.reduce_mean(tf.square(D_Y_real - 1.0)) + \\\r\n",
        "            tf.reduce_mean(tf.square(D_Y_fake_sample))) / 2.0\r\n",
        "loss_D_X = (tf.reduce_mean(tf.square(D_X_real - 1.0)) + \\\r\n",
        "            tf.reduce_mean(tf.square(D_X_fake_sample))) / 2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KABmsHgVFM3F"
      },
      "source": [
        "tf.reset_default_graph()\r\n",
        "from cadl.cycle_gan import cycle_gan\r\n",
        "net = cycle_gan(img_size=img_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw2ieNMTFPxn"
      },
      "source": [
        "list(net.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKyMa2bcFRhE"
      },
      "source": [
        "\r\n",
        "training_vars = tf.trainable_variables()\r\n",
        "D_X_vars = [v for v in training_vars if v.name.startswith('D_X')]\r\n",
        "D_Y_vars = [v for v in training_vars if v.name.startswith('D_Y')]\r\n",
        "G_xy_vars = [v for v in training_vars if v.name.startswith('G_xy')]\r\n",
        "G_yx_vars = [v for v in training_vars if v.name.startswith('G_yx')]\r\n",
        "G_vars = G_xy_vars + G_yx_vars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEd4bVZSFVOM"
      },
      "source": [
        "learning_rate = 0.001\r\n",
        "D_X = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(\r\n",
        "        net['loss_D_X'], var_list=D_X_vars)\r\n",
        "D_Y = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(\r\n",
        "        net['loss_D_Y'], var_list=D_Y_vars)\r\n",
        "G = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(\r\n",
        "        net['loss_G'], var_list=G_vars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m_g5h-rFXHP"
      },
      "source": [
        "print(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODzZitA9FZYl"
      },
      "source": [
        "# How many fake generations to keep around\r\n",
        "capacity = 50\r\n",
        "\r\n",
        "# Storage for fake generations\r\n",
        "fake_Xs = capacity * [np.zeros((1, img_size, img_size, 3), dtype=np.float32)]\r\n",
        "fake_Ys = capacity * [np.zeros((1, img_size, img_size, 3), dtype=np.float32)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmKwJnTPFcz0"
      },
      "source": [
        "from cadl.cycle_gan import batch_generator_dataset, batch_generator_random_crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8uh0kHtFfoU"
      },
      "source": [
        "# Load your data into imgs1 and imgs2 here!\r\n",
        "# I've loaded in random noise as an example, but you'll want to use\r\n",
        "# plt.imread or skimage to load in images into a list of images\r\n",
        "ds_X, ds_Y = np.random.rand(10, img_size, img_size, 3), \\\r\n",
        "             np.random.rand(10, img_size, img_size, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8rZoBCIFhlc"
      },
      "source": [
        "X_i, Y_i = next(batch_generator_dataset(ds_X, ds_Y))\r\n",
        "X_i.shape, Y_i.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUyv9VyUFjxk"
      },
      "source": [
        "ds_X, ds_Y = np.random.rand(1024, 1024, 3), np.random.rand(1024, 1024, 3)\r\n",
        "X_i, Y_i = next(batch_generator_random_crop(\r\n",
        "        ds_X, ds_Y, min_size=img_size, max_size=512))\r\n",
        "X_i.shape, Y_i.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_eym6yLFl80"
      },
      "source": [
        "idx = 0\r\n",
        "it_i = 0\r\n",
        "n_epochs = 10\r\n",
        "ckpt_path = './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDUz1O9GFqZG"
      },
      "source": [
        "with tf.Session() as sess:\r\n",
        "    # Build an init op for our variables\r\n",
        "    init_op = tf.group(tf.global_variables_initializer(),\r\n",
        "                       tf.local_variables_initializer())\r\n",
        "    sess.run(init_op)\r\n",
        "    \r\n",
        "    # We'll also save our model so we can load it up again\r\n",
        "    saver = tf.train.Saver()\r\n",
        "    writer = tf.summary.FileWriter(ckpt_path)\r\n",
        "    \r\n",
        "    for epoch_i in range(n_epochs):\r\n",
        "        # You'll want to use the approriate batch generator here!\r\n",
        "        for X, Y in batch_generator_random_crop(ds_X, ds_Y):\r\n",
        "\r\n",
        "            # First generate in both directions\r\n",
        "            X_fake, Y_fake = sess.run(\r\n",
        "                [net['X_fake'], net['Y_fake']],\r\n",
        "                feed_dict={net['X_real']: X,\r\n",
        "                           net['Y_real']: Y})\r\n",
        "\r\n",
        "            # Now sample from history\r\n",
        "            if it_i < capacity:\r\n",
        "                # Not enough samples yet, fill up history buffer\r\n",
        "                fake_Xs[idx] = X_fake\r\n",
        "                fake_Ys[idx] = Y_fake\r\n",
        "                idx = (idx + 1) % capacity\r\n",
        "            elif np.random.random() > 0.5:\r\n",
        "                # Swap out a random idx from history\r\n",
        "                rand_idx = np.random.randint(0, capacity)\r\n",
        "                fake_Xs[rand_idx], X_fake = X_fake, fake_Xs[rand_idx]\r\n",
        "                fake_Ys[rand_idx], Y_fake = Y_fake, fake_Ys[rand_idx]\r\n",
        "            else:\r\n",
        "                # Use current generation\r\n",
        "                pass\r\n",
        "\r\n",
        "            # Optimize G Networks\r\n",
        "            loss_G = sess.run(\r\n",
        "                [net['loss_G'], G],\r\n",
        "                feed_dict={\r\n",
        "                    net['X_real']: X,\r\n",
        "                    net['Y_real']: Y,\r\n",
        "                    net['Y_fake_sample']: Y_fake,\r\n",
        "                    net['X_fake_sample']: X_fake\r\n",
        "                })[0]\r\n",
        "\r\n",
        "            # Optimize D_Y\r\n",
        "            loss_D_Y = sess.run(\r\n",
        "                [net['loss_D_Y'], D_Y],\r\n",
        "                feed_dict={\r\n",
        "                    net['X_real']: X,\r\n",
        "                    net['Y_real']: Y,\r\n",
        "                    net['Y_fake_sample']: Y_fake\r\n",
        "                })[0]\r\n",
        "\r\n",
        "            # Optimize D_X\r\n",
        "            loss_D_X = sess.run(\r\n",
        "                [net['loss_D_X'], D_X],\r\n",
        "                feed_dict={\r\n",
        "                    net['X_real']: X,\r\n",
        "                    net['Y_real']: Y,\r\n",
        "                    net['X_fake_sample']: X_fake\r\n",
        "                })[0]\r\n",
        "\r\n",
        "            print(it_i, 'G:', loss_G, 'D_X:', loss_D_X, 'D_Y:', loss_D_Y)\r\n",
        "\r\n",
        "            # Update summaries\r\n",
        "            if it_i % 100 == 0:\r\n",
        "                summary = sess.run(\r\n",
        "                    net['summaries'],\r\n",
        "                    feed_dict={\r\n",
        "                        net['X_real']: X,\r\n",
        "                        net['Y_real']: Y,\r\n",
        "                        net['X_fake_sample']: X_fake,\r\n",
        "                        net['Y_fake_sample']: Y_fake\r\n",
        "                    })\r\n",
        "                writer.add_summary(summary, it_i)\r\n",
        "            it_i += 1\r\n",
        "\r\n",
        "        # Save\r\n",
        "        if epoch_i % 50 == 0:\r\n",
        "            saver.save(\r\n",
        "                sess,\r\n",
        "                os.path.join(ckpt_path, 'model.ckpt'),\r\n",
        "                global_step=epoch_i)\r\n",
        "            \r\n",
        "        # Show generative images:        \r\n",
        "        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\r\n",
        "        axs[0][0].set_title('X Real')\r\n",
        "        axs[0][0].imshow(np.clip(X[0], 0.0, 1.0))\r\n",
        "        axs[0][1].set_title('X Fake')\r\n",
        "        axs[0][1].imshow(np.clip(X_fake[0], 0.0, 1.0))\r\n",
        "        axs[1][0].set_title('Y')\r\n",
        "        axs[1][0].imshow(np.clip(Y[0], 0.0, 1.0))\r\n",
        "        axs[1][1].set_title('Y Fake')\r\n",
        "        axs[1][1].imshow(np.clip(Y_fake[0], 0.0, 1.0))\r\n",
        "        fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm-KYH9jFxwU"
      },
      "source": [
        "\r\n",
        "plt.figure(figsize=(13,10))\r\n",
        "plt.imshow(plt.imread('CycleGAN/imgs/terrain-generation.png'))\r\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibaYK2EHFz6k"
      },
      "source": [
        "\r\n",
        "plt.figure(figsize=(13,10))\r\n",
        "plt.imshow(plt.imread('CycleGAN/imgs/character-generation.png'))\r\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZGq3XmeF2z7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}